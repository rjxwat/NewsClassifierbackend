{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://10.50.43.246:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [01/Apr/2025 06:25:25] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Apr/2025 06:25:25] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed input tensor shape: torch.Size([1, 4, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Apr/2025 06:25:38] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Apr/2025 06:25:38] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed input tensor shape: torch.Size([1, 4, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Apr/2025 06:25:54] \"OPTIONS /predict-and-log HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Apr/2025 06:25:54] \"POST /predict-and-log HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed input tensor shape: torch.Size([1, 4, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Apr/2025 06:26:18] \"OPTIONS /predict-and-log HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Apr/2025 06:26:18] \"POST /predict-and-log HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed input tensor shape: torch.Size([1, 4, 16])\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from flask_cors import CORS\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from flask import send_from_directory\n",
    "\n",
    "\n",
    "# Load word2idx mapping\n",
    "with open(\"word2idx.pkl\", \"rb\") as f:\n",
    "    word2idx = pickle.load(f)\n",
    "\n",
    "# Load trained model\n",
    "checkpoint = torch.load(\"final_model.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# Constants\n",
    "PAD_WORD = \"<PAD>\"\n",
    "MAX_SENT_LEN = 16\n",
    "MAX_SENT_NUM = 4\n",
    "EMBED_DIM = 200  # Updated to match the trained model\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# Define CNN Model\n",
    "class WordCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=100, num_filters=10, kernel_sizes=[2, 3, 4], padding_idx=0):\n",
    "        super(WordCNN, self).__init__()\n",
    "        self.trainable_embedding = nn.Embedding(vocab_size, 100, padding_idx=padding_idx)\n",
    "        self.static_embedding = nn.Embedding(vocab_size, 100, padding_idx=padding_idx)\n",
    "\n",
    "        self.static_embedding.weight.requires_grad = False\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, num_filters, (k, 200)) for k in kernel_sizes\n",
    "        ])\n",
    "        self.output_dim = num_filters * len(kernel_sizes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_sentences, sentence_len = x.shape\n",
    "        embedded_trainable = self.trainable_embedding(x)  # [batch,4,16,100]\n",
    "        embedded_static = self.static_embedding(x)  # [batch,4,16,100]\n",
    "    \n",
    "    # Concatenate embeddings (200D)\n",
    "        embedded = torch.cat((embedded_trainable, embedded_static), dim=-1)\n",
    "    \n",
    "        embedded = embedded.view(batch_size * num_sentences, 1, sentence_len, -1)\n",
    "        conv_outs = [F.max_pool1d(F.relu(conv(embedded)).squeeze(3), conv(embedded).size(2)).squeeze(2) for conv in self.convs]\n",
    "        out = torch.cat(conv_outs, dim=1).view(batch_size, num_sentences, -1)\n",
    "        return out\n",
    "\n",
    "# Define Attention Layer\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.score = nn.Linear(hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, lstm_out):\n",
    "        attn_weights = torch.softmax(self.score(torch.tanh(self.attn(lstm_out))).squeeze(2), dim=1)\n",
    "        context_vector = torch.sum(lstm_out * attn_weights.unsqueeze(2), dim=1)\n",
    "        return context_vector\n",
    "\n",
    "# Define LSTM Model\n",
    "class SentenceLSTMWithAttention(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
    "        super(SentenceLSTMWithAttention, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        context_vector = self.attention(lstm_out)\n",
    "        return self.fc(context_vector)\n",
    "\n",
    "# Initialize models\n",
    "vocab_size = len(word2idx)\n",
    "cnn_model = WordCNN(vocab_size, embed_dim=EMBED_DIM)\n",
    "lstm_model = SentenceLSTMWithAttention(cnn_model.output_dim, 128, 2, NUM_CLASSES)\n",
    "\n",
    "# Load trained weights\n",
    "cnn_model.load_state_dict(checkpoint['cnn_model_state_dict'])\n",
    "lstm_model.load_state_dict(checkpoint['lstm_model_state_dict'])\n",
    "cnn_model.eval()\n",
    "lstm_model.eval()\n",
    "\n",
    "# Flask API\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # This enables CORS for all routes\n",
    "\n",
    "# OR for more control:\n",
    "CORS(app, resources={\n",
    "    r\"/predict\": {\"origins\": \"*\"},\n",
    "    r\"/predict-and-log\": {\"origins\": \"*\"}\n",
    "})\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text_clean = re.sub(r'[^\\w\\s]', ' ', text.lower()).split()\n",
    "\n",
    "    # Convert words to indices\n",
    "    chunks = []\n",
    "    for i in range(0, len(text_clean), MAX_SENT_LEN):\n",
    "        chunk = [word2idx.get(word, word2idx.get(\"<UNK>\", 1)) for word in text_clean[i:i+MAX_SENT_LEN]]\n",
    "        # Pad if needed\n",
    "        while len(chunk) < MAX_SENT_LEN:\n",
    "            chunk.append(word2idx.get(PAD_WORD, 0))\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    # Ensure exactly MAX_SENT_NUM sentences\n",
    "    while len(chunks) < MAX_SENT_NUM:\n",
    "        chunks.append([word2idx.get(PAD_WORD, 0)] * MAX_SENT_LEN)\n",
    "\n",
    "    # Convert to tensor\n",
    "    input_tensor = torch.tensor(chunks[:MAX_SENT_NUM], dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    print(f\"Processed input tensor shape: {input_tensor.shape}\")  # Debugging output\n",
    "    return input_tensor\n",
    "\n",
    "\n",
    "CSV_FILE = \"predictions_log.csv\"\n",
    "if not os.path.exists(CSV_FILE):\n",
    "    with open(CSV_FILE, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"timestamp\", \"text_snippet\", \"predicted_class\", \"full_text_length\"])\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    text = data.get(\"text\", \"\")\n",
    "    \n",
    "    if not text:\n",
    "        return jsonify({\"error\": \"No text provided\"}), 400\n",
    "    \n",
    "    input_tensor = preprocess_text(text)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        cnn_output = cnn_model(input_tensor)\n",
    "        prediction = lstm_model(cnn_output)\n",
    "        predicted_class = torch.argmax(prediction, dim=1).item()\n",
    "        confidence = torch.softmax(prediction, dim=1)[0][predicted_class].item()\n",
    "    \n",
    "    return jsonify({\n",
    "        \"prediction\": predicted_class,\n",
    "        \"confidence\": float(confidence)\n",
    "    })\n",
    "@app.route('/predict-and-log', methods=['POST'])\n",
    "def predict_and_log():\n",
    "    data = request.get_json()\n",
    "    text = data.get(\"text\", \"\")\n",
    "    \n",
    "    # First get prediction\n",
    "    pred_response = predict()\n",
    "    if pred_response.status_code != 200:\n",
    "        return pred_response\n",
    "    \n",
    "    prediction_data = pred_response.get_json()\n",
    "    \n",
    "    # Log to CSV\n",
    "    with open(CSV_FILE, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            datetime.now().isoformat(),\n",
    "            text[:50] + \"...\" if len(text) > 50 else text,\n",
    "            prediction_data[\"prediction\"],\n",
    "            len(text)\n",
    "        ])\n",
    "    \n",
    "    return jsonify({\n",
    "        **prediction_data,\n",
    "        \"logged\": True\n",
    "    })\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return send_from_directory('.', 'index.html')\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
